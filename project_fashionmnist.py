# -*- coding: utf-8 -*-
"""project-FashionMNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/145rR19yfJnttVi0Z_Y4qeV4FJEV6bTY-
"""

import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist

# Load Fashion MNIST dataset
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# Preprocessing
# Reshape and normalize the images
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')

# Normalize pixel values to the range of [0, 1]
train_images /= 255.0
test_images /= 255.0

# Convert labels to one-hot encoding
train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)
test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)

# Print the shape of datasets
print("Training images shape:", train_images.shape)
print("Training labels shape:", train_labels.shape)
print("Testing images shape:", test_images.shape)
print("Testing labels shape:", test_labels.shape)

"""# **simple** **gan**"""

import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.datasets import fashion_mnist

# Load Fashion MNIST dataset
(train_images, train_labels), (_, _) = fashion_mnist.load_data()

# Define the class labels
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Define the number of images to display
num_images = 5

# Plot the images
plt.figure(figsize=(10, 5))
for i in range(num_images):
    plt.subplot(1, num_images, i+1)
    plt.imshow(train_images[i], cmap='gray')
    plt.title(class_names[train_labels[i]])
    plt.axis('off')
plt.show()

"""# **Simple** **GAN**"""

import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
import numpy as np
import matplotlib.pyplot as plt

# Define the generator model
def build_generator(latent_dim):
    model = models.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(latent_dim,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    return model

# Define the discriminator model
def build_discriminator():
    model = models.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))
    return model

# Define the loss functions
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

# Define the generator and discriminator models
latent_dim = 100
generator = build_generator(latent_dim)
discriminator = build_discriminator()

# Define the optimizers for generator and discriminator
generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

# Define the training loop
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, latent_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)
        disc_loss_real = cross_entropy(tf.ones_like(real_output), real_output)
        disc_loss_fake = cross_entropy(tf.zeros_like(fake_output), fake_output)
        disc_loss = disc_loss_real + disc_loss_fake

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

# Define the training parameters
EPOCHS = 100
BATCH_SIZE = 256
BUFFER_SIZE = train_images.shape[0]
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

# Train the GAN
for epoch in range(EPOCHS):
    for image_batch in train_dataset:
        train_step(image_batch)

    if (epoch + 1) % 10 == 0:
        print(f'Epoch {epoch + 1}/{EPOCHS}')

# Generate and save images
num_examples_to_generate = 16
noise = tf.random.normal([num_examples_to_generate, latent_dim])
generated_images = generator(noise, training=False)

# Rescale images from [-1, 1] to [0, 1]
generated_images = (generated_images + 1) / 2

# Plot generated images
plt.figure(figsize=(4, 4))
for i in range(num_examples_to_generate):
    plt.subplot(4, 4, i+1)
    plt.imshow(generated_images[i, :, :, 0], cmap='gray')
    plt.axis('off')
plt.show()

# Generate and save images
num_examples_to_generate = 1000  # Adjust as needed
noise = tf.random.normal([num_examples_to_generate, latent_dim])
generated_images = generator(noise, training=False)

# Rescale images from [-1, 1] to [0, 1]
generated_images = (generated_images + 1) / 2

import tensorflow as tf
import numpy as np
from scipy.stats import entropy

# Define a function to calculate the Inception Score (IS)
def calculate_inception_score(generated_images, num_splits=10):
    # Load pre-trained InceptionV3 model
    inception_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(299, 299, 3))

    # Preprocess generated images and resize to 299x299
    generated_images_resized = tf.image.resize(generated_images, (299, 299))

    # Convert grayscale images to RGB format
    generated_images_rgb = tf.repeat(generated_images_resized, 3, axis=-1)

    # Calculate predictions for generated images using InceptionV3 model
    preds = inception_model.predict(generated_images_rgb)

    # Calculate conditional class probabilities (p(y|x)) by averaging softmax probabilities over samples
    preds_yx = np.mean(tf.nn.softmax(preds, axis=-1), axis=0)

    # Calculate marginal class probabilities (p(y)) by averaging softmax probabilities over samples and classes
    preds_y = np.mean(preds_yx, axis=0)

    # Calculate the KL divergence for each split
    kl_divs = []
    for i in range(num_splits):
        # Split the predictions into sub-arrays
        start_idx = (i * preds.shape[0]) // num_splits
        end_idx = ((i + 1) * preds.shape[0]) // num_splits
        preds_split = preds[start_idx:end_idx]

        # Calculate the conditional class probabilities for the split
        preds_yx_split = np.mean(tf.nn.softmax(preds_split, axis=-1), axis=0)

        # Compute the KL divergence between the conditional and marginal distributions
        kl_div = entropy(preds_yx_split.T, qk=preds_yx.T)
        kl_divs.append(kl_div)

    # Calculate the mean and standard deviation of the KL divergences
    mean_kl_div = np.mean(kl_divs)
    std_kl_div = np.std(kl_divs)

    # Calculate the Inception Score as exp(mean(KL)) with correction for the standard deviation
    inception_score = np.exp(mean_kl_div - std_kl_div)

    return inception_score

# Example usage:
# generated_images should be a NumPy array of generated images (shape: [num_samples, height, width, channels])
# where num_samples is the number of generated images
# and channels is the number of color channels (3 for RGB)
inception_score = calculate_inception_score(generated_images)
print(f"Inception Score: {inception_score}")

from google.colab import drive
drive.mount('/content/drive')

"""# **GAN**"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU, Dropout, Conv2D, Conv2DTranspose, BatchNormalization
from tensorflow.keras.models import Sequential
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt

def make_generator_model():
    model = Sequential([
        Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)),
        BatchNormalization(),
        LeakyReLU(),
        Reshape((7, 7, 256)),
        Conv2DTranspose(128, kernel_size=5, strides=1, padding='same', use_bias=False),
        BatchNormalization(),
        LeakyReLU(),
        Conv2DTranspose(64, kernel_size=5, strides=2, padding='same', use_bias=False),
        BatchNormalization(),
        LeakyReLU(),
        Conv2DTranspose(1, kernel_size=5, strides=2, padding='same', use_bias=False, activation='tanh')
    ])
    return model

def make_discriminator_model():
    model = Sequential([
        Conv2D(64, kernel_size=5, strides=2, padding='same', input_shape=[28, 28, 1]),
        LeakyReLU(),
        Dropout(0.3),
        Conv2D(128, kernel_size=5, strides=2, padding='same'),
        LeakyReLU(),
        Dropout(0.3),
        Flatten(),
        Dense(1)
    ])
    return model

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    smoothed_labels_real = tf.ones_like(real_output) * 0.9  # Label smoothing
    smoothed_labels_fake = tf.zeros_like(fake_output)
    real_loss = cross_entropy(smoothed_labels_real, real_output)
    fake_loss = cross_entropy(smoothed_labels_fake, fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

# Use legacy versions of the Adam optimizer
generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)

def train_step(images):
    batch_size = images.shape[0]
    noise = tf.random.normal([batch_size, 100])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        noise_real = 0.05 * tf.random.normal([batch_size, 28, 28, 1])
        noise_fake = 0.05 * tf.random.normal([batch_size, 28, 28, 1])

        real_output = discriminator(images + noise_real, training=True)
        fake_output = discriminator(generated_images + noise_fake, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

# Modified train function to avoid `@tf.function`
def train(dataset, epochs):
    for epoch in range(epochs):
        for image_batch in dataset:
            train_step(image_batch)

BUFFER_SIZE = 60000
BATCH_SIZE = 256
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
EPOCHS = 50

# Training loop with print statements
for epoch in range(EPOCHS):
    print(f"Epoch {epoch + 1}/{EPOCHS}")
    for i, image_batch in enumerate(train_dataset):
        train_step(image_batch)
        print(f"\rBatch {i+1}/{len(train_images)//BATCH_SIZE}", end='')
    print()

import matplotlib.pyplot as plt

def generate_save_and_display_images(model, epoch, test_input):
    predictions = model(test_input, training=False)
    fig = plt.figure(figsize=(4, 4))
    generated_images = []

    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i+1)
        generated_image = predictions[i, :, :, 0] * 127.5 + 127.5  # Assuming grayscale images
        plt.imshow(generated_image, cmap='gray')
        plt.axis('off')
        generated_images.append(generated_image)

    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()

    return generated_images

# Generate random noise
noise = tf.random.normal([16, 100])
generated_images = generate_save_and_display_images(generator, 0, noise)

# Generate and save images
num_examples_to_generate = 1000  # Adjust as needed
noise = tf.random.normal([num_examples_to_generate, latent_dim])
generated_images = generator(noise, training=False)

# Rescale images from [-1, 1] to [0, 1]
generated_images = (generated_images + 1) / 2

import tensorflow as tf
import numpy as np
from scipy.stats import entropy

# Define a function to calculate the Inception Score (IS)
def calculate_inception_score(generated_images, num_splits=10):
    # Load pre-trained InceptionV3 model
    inception_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(299, 299, 3))

    # Preprocess generated images and resize to 299x299
    generated_images_resized = tf.image.resize(generated_images, (299, 299))

    # Convert grayscale images to RGB format
    generated_images_rgb = tf.repeat(generated_images_resized, 3, axis=-1)

    # Calculate predictions for generated images using InceptionV3 model
    preds = inception_model.predict(generated_images_rgb)

    # Calculate conditional class probabilities (p(y|x)) by averaging softmax probabilities over samples
    preds_yx = np.mean(tf.nn.softmax(preds, axis=-1), axis=0)

    # Calculate marginal class probabilities (p(y)) by averaging softmax probabilities over samples and classes
    preds_y = np.mean(preds_yx, axis=0)

    # Calculate the KL divergence for each split
    kl_divs = []
    for i in range(num_splits):
        # Split the predictions into sub-arrays
        start_idx = (i * preds.shape[0]) // num_splits
        end_idx = ((i + 1) * preds.shape[0]) // num_splits
        preds_split = preds[start_idx:end_idx]

        # Calculate the conditional class probabilities for the split
        preds_yx_split = np.mean(tf.nn.softmax(preds_split, axis=-1), axis=0)

        # Compute the KL divergence between the conditional and marginal distributions
        kl_div = entropy(preds_yx_split.T, qk=preds_yx.T)
        kl_divs.append(kl_div)

    # Calculate the mean and standard deviation of the KL divergences
    mean_kl_div = np.mean(kl_divs)
    std_kl_div = np.std(kl_divs)

    # Calculate the Inception Score as exp(mean(KL)) with correction for the standard deviation
    inception_score = np.exp(mean_kl_div - std_kl_div)

    return inception_score

# Example usage:
# generated_images should be a NumPy array of generated images (shape: [num_samples, height, width, channels])
# where num_samples is the number of generated images
# and channels is the number of color channels (3 for RGB)
inception_score = calculate_inception_score(generated_images)
print(f"Inception Score: {inception_score}")

"""# **VAE**"""

import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np

# Load dataset
(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()

# Normalize and reshape the images
train_images = train_images.astype('float32') / 255.
test_images = test_images.astype('float32') / 255.

train_images = train_images[..., tf.newaxis]
test_images = test_images[..., tf.newaxis]

latent_dim = 64  # Increase latent dimension

# Modify the encoder model
encoder_inputs = layers.Input(shape=(28, 28, 1))
x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(encoder_inputs)
x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)
x = layers.Flatten()(x)
x = layers.Dense(64, activation='relu')(x)  # Increased to match larger latent space
z_mean = layers.Dense(latent_dim)(x)
z_log_var = layers.Dense(latent_dim)(x)

encoder = models.Model(encoder_inputs, [z_mean, z_log_var], name='encoder')
encoder.summary()

print(z_mean)

latent_inputs = layers.Input(shape=(latent_dim,))
x = layers.Dense(7*7*128, activation='relu')(latent_inputs)  # Increased capacity to handle more complex representations
x = layers.Reshape((7, 7, 128))(x)
x = layers.Conv2DTranspose(128, 3, activation='relu', strides=2, padding='same')(x)
x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)
decoder_outputs = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)

decoder = models.Model(latent_inputs, decoder_outputs, name='decoder')
decoder.summary()

class VAE(models.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder

    def call(self, inputs):
        z_mean, z_log_var = self.encoder(inputs)
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        z = z_mean + tf.exp(0.5 * z_log_var) * epsilon
        reconstructed = self.decoder(z)
        kl_loss = -0.5 * tf.reduce_sum(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1, axis=-1)
        self.add_loss(tf.reduce_mean(kl_loss))
        return reconstructed

vae = VAE(encoder, decoder)
vae.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())

(x_train, _), (x_test, _) = fashion_mnist.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

vae.fit(x_train, x_train, epochs=100, batch_size=64, validation_data=(x_test, x_test))

def plot_images(images, n=10, title="Generated Images"):
    plt.figure(figsize=(20, 2))
    for i in range(n):
        ax = plt.subplot(1, n, i + 1)
        plt.imshow(images[i].reshape(28, 28), cmap='gray')
        plt.axis('off')
    plt.title(title)
    plt.show()

random_latent_vectors = tf.random.normal(shape=(10, latent_dim))
generated_images = decoder.predict(random_latent_vectors)
plot_images(generated_images)

# Assuming you have trained the VAE model and have access to the test dataset
# Evaluate the reconstruction loss on the test dataset
mse = vae.evaluate(test_images, test_images)
print("Reconstruction Loss (MSE):", mse)

"""# **PixelCNN**"""

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Activation, BatchNormalization, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
import numpy as np
import matplotlib.pyplot as plt

(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()

# Normalize and add channel dimension
x_train = np.expand_dims(x_train, -1) / 255.
x_test = np.expand_dims(x_test, -1) / 255.

# Convert to float32
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, ReLU, Add, Layer
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt

# Using more stable activations and initializations
class MaskedConv2D(Conv2D):
    def __init__(self, filters, kernel_size, mask_type, **kwargs):
        super(MaskedConv2D, self).__init__(filters, kernel_size, **kwargs)
        self.mask_type = mask_type

    def build(self, input_shape):
        super(MaskedConv2D, self).build(input_shape)
        mask = np.ones(self.kernel.shape, dtype=np.float32)
        center = self.kernel_size[0] // 2, self.kernel_size[1] // 2
        mask[center[0] + 1:, :, :, :] = 0.
        mask[center[0], center[1] + (self.mask_type == 'B'):, :, :] = 0.
        self.mask = self.add_weight(name='mask', shape=mask.shape, trainable=False, initializer=tf.constant_initializer(mask))

    def call(self, inputs):
        self.kernel.assign(self.kernel * self.mask)
        return super(MaskedConv2D, self).call(inputs)

inputs = Input(shape=(28, 28, 1))
x = MaskedConv2D(64, (7, 7), 'A', padding='same', activation='relu')(inputs)

for _ in range(4):  # Deeper network
    x = BatchNormalization()(x)  # Adding batch normalization
    x = ReLU()(x)
    x = MaskedConv2D(64, (7, 7), 'B', padding='same', activation='relu')(x)

x = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(x)  # Ensure the output is between 0 and 1

model = Model(inputs, x)
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')
model.summary()

# Training the model
model.fit(x_train, x_train, epochs=50, batch_size=128, validation_split=0.1)  # Increased epochs and added validation split

# Function to generate images
def generate_images(model, num_samples=10):
    samples = np.zeros((num_samples, 28, 28, 1), dtype='float32')
    for i in range(28):  # Iterate over each pixel position
        for j in range(28):
            next_pixel_probs = model.predict(samples)[:, i, j, 0]
            samples[:, i, j, 0] = np.random.binomial(1, next_pixel_probs)  # Sample from a Bernoulli distribution
    return samples

# Generate and display images
generated_images = generate_images(model, num_samples=10)
fig, axes = plt.subplots(1, 10, figsize=(20, 2))
for i, ax in enumerate(axes):
    ax.imshow(generated_images[i].squeeze(), cmap='gray')
    ax.axis('off')
plt.show()

import numpy as np
from scipy.linalg import sqrtm
from sklearn.metrics import pairwise_distances
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from PIL import Image

def calculate_fid(real_images, fake_images, batch_size=64):
    # Load pre-trained InceptionV3 model
    inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))

    # Function to preprocess images for InceptionV3
    def preprocess_images(images):
        images_resized = [Image.fromarray((image.squeeze() * 255).astype('uint8')).resize((299, 299)) for image in images]
        images_resized = [np.array(image) for image in images_resized]
        images_resized = np.array(images_resized)
        images_resized = preprocess_input(images_resized)
        return images_resized

    # Preprocess real and fake images for InceptionV3
    real_images_processed = preprocess_images(real_images)
    fake_images_processed = preprocess_images(fake_images)

    # Generate features for real and fake images
    real_features = inception.predict(real_images_processed, batch_size=batch_size)
    fake_features = inception.predict(fake_images_processed, batch_size=batch_size)

    # Compute mean and covariance for real and fake features
    mean_real, cov_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)
    mean_fake, cov_fake = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)

    # Compute squared Frobenius norm between mean and covariance
    fid = np.sum((mean_real - mean_fake) ** 2) + np.trace(cov_real + cov_fake - 2 * sqrtm(cov_real.dot(cov_fake)))
    return fid

# Generate fake images using the trained model
generated_images = generate_images(model, num_samples=100)

# Calculate FID score
fid_score = calculate_fid(x_test[:100], generated_images)
print("FID Score:", fid_score)